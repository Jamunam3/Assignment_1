{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "\n",
    "# Establish connection\n",
    "mydb = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"Sindhuravi@3\"\n",
    ")\n",
    "\n",
    "# Check if the connection was successful\n",
    "if mydb.is_connected():\n",
    "    print(\"Connection successful\")\n",
    "else:\n",
    "    print(\"Connection failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mysql.connector.connection_cext.CMySQLConnection object at 0x0000019C63691580>\n",
      "the databases created\n",
      "employeedb\n",
      "information_schema\n",
      "mysql\n",
      "performance_schema\n",
      "records\n",
      "sakila\n",
      "sportradar\n",
      "sys\n",
      "world\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "\n",
    "mydb=mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"Sindhuravi@3\",\n",
    ")\n",
    "\n",
    "print(mydb)\n",
    "Mycursor=mydb.cursor(buffered=True)  # cursor is intracting point between mysql and python\n",
    "\n",
    "# create database\n",
    "Mycursor.execute('create database SportRadar')\n",
    "print('the databases created')\n",
    "\n",
    "# Show database\n",
    "Mycursor.execute('show databases')\n",
    "for i in Mycursor:\n",
    "    print(''.join(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5839 entries, 0 to 5838\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   category_id    5839 non-null   object\n",
      " 1   category_name  5839 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 91.4+ KB\n",
      "the table has been created\n",
      "The data has been uploaded. Total rows in table: 18\n"
     ]
    }
   ],
   "source": [
    "# import file to store\n",
    "df=pd.read_csv(r'C:\\Users\\jamun\\Desktop\\Tennis_SportRadar_Api\\env\\Scripts\\Categories_Table.csv')\n",
    "Categories_table=df.copy()\n",
    "\n",
    "# Data preprocessing\n",
    "\n",
    "#information about the dataset\n",
    "Categories_table.info()\n",
    "# drop duplicates\n",
    "Categories_table.drop_duplicates(subset=['category_id'],inplace=True)\n",
    "\n",
    "\n",
    "# create table \n",
    "Mycursor.execute('create table SportRadar.Categories_table(category_id varchar(50),category_name varchar(100) not null,PRIMARY KEY (category_id))')\n",
    "print('the table has been created')\n",
    "\n",
    "# values to store \n",
    "insert_into='insert ignore into SportRadar.Categories_Table(category_id,category_name) values(%s,%s)'\n",
    "\n",
    "#insert the rows through the loop\n",
    "for index,row in Categories_table.iterrows():\n",
    "    try:\n",
    "        Mycursor.execute(insert_into,(row['category_id'],row['category_name']))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting row {index}: {row.to_dict()}\\nError: {e}\")\n",
    "mydb.commit()\n",
    "# ensure the data has been stored\n",
    "Mycursor.execute('select count(*) from SportRadar.Categories_table')\n",
    "row_count=Mycursor.fetchone()[0]\n",
    "print(f'The data has been uploaded. Total rows in table: {row_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5839 entries, 0 to 5838\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   competition_id    5839 non-null   object\n",
      " 1   competition_name  5839 non-null   object\n",
      " 2   parent_id         5766 non-null   object\n",
      " 3   type              5839 non-null   object\n",
      " 4   gender            5839 non-null   object\n",
      " 5   category_id       5839 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 273.8+ KB\n",
      "The data has been uploaded. Total rows in table: 5839\n"
     ]
    }
   ],
   "source": [
    "# import file to store\n",
    "df=pd.read_csv(r'C:\\Users\\jamun\\Desktop\\Tennis_SportRadar_Api\\env\\Scripts\\Competitions_Table.csv')\n",
    "Competitions_table=df.copy()\n",
    "\n",
    "# Data Preprocessing\n",
    "\n",
    "# information about dataset\n",
    "Competitions_table.info()\n",
    "# drop Duplicates by 'competition_id'\n",
    "Competitions_table.drop_duplicates(subset=['competition_id'],inplace=True)\n",
    "\n",
    "# Convert missing values to None (for MySQL compatibility)\n",
    "Competitions_table['parent_id'] = Competitions_table['parent_id'].apply(lambda x: None if pd.isna(x) else x)\n",
    "\n",
    "\n",
    "\n",
    "# create table \n",
    "Mycursor.execute('create table SportRadar.Competitions_table(competition_id varchar(50) ,competition_name varchar(100) not null,parent_id varchar(50) null,type varchar(20) not null,gender varchar(10) not null,category_id varchar(50),primary key(competition_id),FOREIGN KEY (category_id) REFERENCES SportRadar.Categories_table(category_id))')\n",
    "#print('the table has been created')\n",
    "\n",
    "# values to store \n",
    "insert_into='insert ignore into SportRadar.Competitions_table(competition_id,competition_name,parent_id,type,gender,category_id)values(%s,%s,%s,%s,%s,%s)'\n",
    "\n",
    "#insert the rows through the loop\n",
    "for index,row in Competitions_table.iterrows():\n",
    "    try:\n",
    "        Mycursor.execute(insert_into,(row['competition_id'],row['competition_name'],row['parent_id'],row['type'],row['gender'],row['category_id']))\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting row {index}: {row.to_dict()}\\nError: {e}\")\n",
    "        \n",
    "mydb.commit()\n",
    "# ensure the data has been stored\n",
    "Mycursor.execute('select count(*) from SportRadar.Competitions_table')\n",
    "row_count=Mycursor.fetchone()[0]\n",
    "print(f'The data has been uploaded. Total rows in table: {row_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 615 entries, 0 to 614\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   complex_id    615 non-null    object\n",
      " 1   complex_name  615 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 9.7+ KB\n",
      "the table has been created\n",
      "The data has been uploaded. Total rows in table: 615\n"
     ]
    }
   ],
   "source": [
    "# import file to store\n",
    "df=pd.read_csv(r'C:\\Users\\jamun\\Desktop\\Tennis_SportRadar_Api\\env\\Scripts\\Complexes_Table.csv')\n",
    "Complexes_table=df.copy()\n",
    "\n",
    "# Data Preprocessing\n",
    "\n",
    "# information about dataset\n",
    "Complexes_table.info()\n",
    "# drop duplicates\n",
    "Complexes_table.drop_duplicates(subset=['complex_id'],inplace=True)\n",
    "\n",
    "\n",
    "# create table \n",
    "Mycursor.execute('create table SportRadar.Complexes_table(complex_id varchar(50),complex_name varchar(100) not null,primary key(complex_id))')\n",
    "print('the table has been created')\n",
    "\n",
    "# values to store \n",
    "insert_into='insert ignore into SportRadar.Complexes_table(complex_id,complex_name)values(%s,%s)'\n",
    "\n",
    "#insert the rows through the loop\n",
    "for index,row in Complexes_table.iterrows():\n",
    "    try:\n",
    "        Mycursor.execute(insert_into,(row['complex_id'],row['complex_name']))\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting row {index}: {row.to_dict()}\\nError: {e}\")\n",
    "#commit changes        \n",
    "mydb.commit()\n",
    "\n",
    "# ensure the data has been stored\n",
    "Mycursor.execute('select count(*) from SportRadar.Complexes_table')\n",
    "row_count=Mycursor.fetchone()[0]\n",
    "print(f'The data has been uploaded. Total rows in table: {row_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3178 entries, 0 to 3177\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   venue_id      3178 non-null   object\n",
      " 1   venue_name    3178 non-null   object\n",
      " 2   city_name     3178 non-null   object\n",
      " 3   country_name  3178 non-null   object\n",
      " 4   country_code  3178 non-null   object\n",
      " 5   timezone      3178 non-null   object\n",
      " 6   complex_id    3178 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 173.9+ KB\n",
      "venue_id        0\n",
      "venue_name      0\n",
      "city_name       0\n",
      "country_name    0\n",
      "country_code    0\n",
      "timezone        0\n",
      "complex_id      0\n",
      "dtype: int64\n",
      "the table has been created\n",
      "The data has been uploaded. Total rows in table: 3178\n"
     ]
    }
   ],
   "source": [
    "# import file to store\n",
    "df=pd.read_csv(r'C:\\Users\\jamun\\Desktop\\Tennis_SportRadar_Api\\env\\Scripts\\Venues_Table.csv')\n",
    "Venues_table=df.copy()\n",
    "\n",
    "# Data Preprocessing\n",
    "\n",
    "#informtion about the dataset\n",
    "Venues_table.info()\n",
    "#check null values by related columns\n",
    "missing=Venues_table.loc[Venues_table['timezone'].isna(),['country_name','city_name','timezone']]\n",
    "missing.drop_duplicates()\n",
    "# mapping the missing timezone\n",
    "fill_missing = {('France', 'Orchies'): 'Europe/Paris',('Singapore', 'Kallang'): 'Asia/Singapore',('China', 'Zhuhai'): 'Asia/Shanghai',('Russia', 'Moscow'): 'Europe/Moscow',('Chile', 'Vina del Mar'): 'America/Santiago',('China', 'Liuzhou'): 'Asia/Shanghai',('Uruguay', 'Punta del Este'): 'America/Montevideo',('Austria', 'Tulln'): 'Europe/Vienna',('Monaco', 'Monte Carlo'): 'Europe/Paris',('Germany', 'Baden-Wurttemberg'): 'Europe/Berlin',('Switzerland', 'Montreux'): 'Europe/Zurich',('China', 'Jiujiang'): 'Asia/Shanghai',('France', 'Decines-Charpieu'): 'Europe/Paris',('Thailand','Nonthaburi'):'Asia/Bangkok'}\n",
    "# fill missing values by 'combine key' column\n",
    "Venues_table['combined_key'] = list(zip(Venues_table['country_name'], Venues_table['city_name']))\n",
    "Venues_table['timezone'] = Venues_table['combined_key'].map(fill_missing).fillna(Venues_table['timezone'])\n",
    "#drop the column\n",
    "Venues_table.drop(columns=['combined_key'], inplace=True)\n",
    "# check null values are there  \n",
    "print(Venues_table.isna().sum())\n",
    "\n",
    "\n",
    "\n",
    "# create table \n",
    "Mycursor.execute('create table SportRadar.Venues_table(venue_id varchar(50),venue_name varchar(100) not null,city_name varchar(100) not null,country_name varchar(100) not null,country_code char(3) not null,timezone varchar(100) not null,complex_id varchar(50),primary key(venue_id),foreign key (complex_id) references SportRadar.Complexes_table(complex_id))')\n",
    "print('the table has been created')\n",
    "\n",
    "# values to store \n",
    "insert_into='insert ignore into SportRadar.Venues_table(venue_id,venue_name,city_name,country_name,country_code,timezone,complex_id)values(%s,%s,%s,%s,%s,%s,%s)'\n",
    "\n",
    "#insert the rows through the loop\n",
    "for index,row in Venues_table.iterrows():\n",
    "    try:\n",
    "        Mycursor.execute(insert_into,(row['venue_id'],row['venue_name'],row['city_name'],row['country_name'],row['country_code'],row['timezone'],row['complex_id']))\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting row {index}: {row.to_dict()}\\nError: {e}\")\n",
    "\n",
    "#commit changes\n",
    "mydb.commit()\n",
    "\n",
    "# ensure the data has been stored\n",
    "Mycursor.execute('select count(*) from SportRadar.Venues_table')\n",
    "row_count=Mycursor.fetchone()[0]\n",
    "print(f'The data has been uploaded. Total rows in table: {row_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   rank_id              1000 non-null   int64 \n",
      " 1   rank                 1000 non-null   int64 \n",
      " 2   movement             1000 non-null   int64 \n",
      " 3   points               1000 non-null   int64 \n",
      " 4   competitions_played  1000 non-null   int64 \n",
      " 5   competitor_id        1000 non-null   object\n",
      "dtypes: int64(5), object(1)\n",
      "memory usage: 47.0+ KB\n",
      "rank_id                0\n",
      "rank                   0\n",
      "movement               0\n",
      "points                 0\n",
      "competitions_played    0\n",
      "competitor_id          0\n",
      "dtype: int64\n",
      "the table has been created\n",
      "The data has been uploaded. Total rows in table: 1\n"
     ]
    }
   ],
   "source": [
    "# import file to store\n",
    "df=pd.read_csv(r'C:\\Users\\jamun\\Desktop\\Tennis_SportRadar_Api\\env\\Scripts\\Competitor_Rankings_Table.csv')\n",
    "Competitor_Rankings_table=df.copy()\n",
    "\n",
    "\n",
    "# Data Preprocessing\n",
    "\n",
    "# information about dataset\n",
    "Competitor_Rankings_table.info()\n",
    "# drop duplicates\n",
    "Competitor_Rankings_table.drop_duplicates(subset=['rank_id'],inplace=True)\n",
    "# check null values\n",
    "print(Competitor_Rankings_table.isna().sum())\n",
    "\n",
    "\n",
    "# create table \n",
    "Mycursor.execute('create table SportRadar.Competitor_Rankings_table(rank_id int AUTO_INCREMENT ,`rank` int not null,movement int not null,points int not null,competitions_played int not null,competitor_id varchar(50),primary key (rank_id),FOREIGN KEY (competitor_id) REFERENCES SportRadar.competitors_table(competitor_id))')\n",
    "print('the table has been created')\n",
    "\n",
    "# values to store \n",
    "insert_into='insert ignore into SportRadar.Competitor_Rankings_table(`rank`,movement,points,competitions_played,competitor_id)values(%s,%s,%s,%s,%s)'\n",
    "\n",
    "#insert the rows through the loop\n",
    "for index,row in Competitor_Rankings_table.iterrows():\n",
    "    try:\n",
    "        Mycursor.execute(insert_into,(row['rank'],row['movement'],row['points'],row['competitions_played'],row['competitor_id']))\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting row {index}: {row.to_dict()}\\nError: {e}\")\n",
    "\n",
    "# committ changes\n",
    "mydb.commit()\n",
    "\n",
    "# ensure the data has been stored\n",
    "Mycursor.execute('select count(*) from SportRadar.Competitor_Rankings_table')\n",
    "row_count=Mycursor.fetchone()[0]\n",
    "print(f'The data has been uploaded. Total rows in table: {row_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   competitor_id  1000 non-null   object\n",
      " 1   name           1000 non-null   object\n",
      " 2   country        1000 non-null   object\n",
      " 3   country_code   934 non-null    object\n",
      " 4   abbreviation   1000 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 39.2+ KB\n",
      "competitor_id    0\n",
      "name             0\n",
      "country          0\n",
      "country_code     0\n",
      "abbreviation     0\n",
      "dtype: int64\n",
      "the table has been created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jamun\\AppData\\Local\\Temp\\ipykernel_2056\\3371345091.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  competitors_table['country_code'].fillna('NTL',inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data has been uploaded. Total rows in table: 1000\n"
     ]
    }
   ],
   "source": [
    "# import file to store\n",
    "df=pd.read_csv(r'C:\\Users\\jamun\\Desktop\\Tennis_SportRadar_Api\\env\\Scripts\\Competitors_Table.csv')\n",
    "competitors_table=df.copy()\n",
    "\n",
    "# Data Preprocessing\n",
    "\n",
    "# information about dataet\n",
    "competitors_table.info()\n",
    "# Drop duplicate rows based on 'competitor_id'\n",
    "competitors_table.drop_duplicates(subset=['competitor_id'],inplace=True)\n",
    "# check null values\n",
    "competitors_table.loc[competitors_table['country_code'].isna(),'country']\n",
    "competitors_table[competitors_table['country']=='Neutral']\n",
    "competitors_table['country_code'].fillna('NTL',inplace=True)\n",
    "# ensure the null values\n",
    "print(competitors_table.isna().sum())\n",
    "\n",
    "\n",
    "# create table \n",
    "Mycursor.execute('create table SportRadar.competitors_table(competitor_id varchar(50),name varchar(100) not null,country varchar(100) not null,country_code char(3) not null,abbreviation varchar(10) not null,primary key (competitor_id))')\n",
    "print('the table has been created')\n",
    "\n",
    "# values to store \n",
    "insert_into='insert ignore into SportRadar.competitors_table(competitor_id,name,country,country_code,abbreviation)values(%s,%s,%s,%s,%s)'\n",
    "\n",
    "#insert the rows through the loop\n",
    "for index,row in competitors_table.iterrows():\n",
    "    try:\n",
    "        Mycursor.execute(insert_into,(row['competitor_id'],row['name'],row['country'],row['country_code'],row['abbreviation']))\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting row {index}: {row.to_dict()}\\nError: {e}\")\n",
    "\n",
    "# committ chanes        \n",
    "mydb.commit()\n",
    "\n",
    "# ensure the data has been stored\n",
    "Mycursor.execute('select count(*) from SportRadar.competitors_table')\n",
    "row_count=Mycursor.fetchone()[0]\n",
    "print(f'The data has been uploaded. Total rows in table: {row_count}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
